{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89a7a18-91c6-4094-b7ff-e7266be79fa5",
   "metadata": {},
   "source": [
    "#### Analysis of EURO-CORDEX annual data\n",
    "\n",
    "- The CARMINE Euro-Cordex selected experiments have an impact on the climate indicators for the CARMINE CSAs in Europe\n",
    "- This notebook is designed to quantify the uncertainties of the indicators for the CSAs and to provide communication material for stakeholders and scientific conferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2214c4-988d-4252-8fb9-2f72fb5c1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start.resolve()] + list(start.resolve().parents):\n",
    "        if (p / \".git\").exists():\n",
    "            return p\n",
    "    raise RuntimeError(\"Could not find repo root (.git not found).\")\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "\n",
    "\n",
    "# In this repository, the dataset tree lives directly under the repo root\n",
    "DATA_ROOT: Path = REPO_ROOT\n",
    "\n",
    "# Outputs (should NOT be committed)\n",
    "OUT_ROOT: Path = REPO_ROOT / \"outputs\"\n",
    "TABLE_DIR: Path = OUT_ROOT / \"tables\"\n",
    "FIG_DIR: Path = OUT_ROOT / \"figures\"\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "#print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"TABLE_DIR exists:\", TABLE_DIR.exists())\n",
    "print(\"FIG_DIR exists:\", FIG_DIR.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a91334-50e0-4feb-ac55-d4c93370dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EURO-CORDEX test data paths (temporary testing workflows)\n",
    "# =============================================================================\n",
    "\n",
    "# Root folder containing zipped EURO-CORDEX test data\n",
    "EUROCORDEX_TESTDATA_ROOT = (\n",
    "    REPO_ROOT / \"2601_EURO_CORDEX_testing_data\"\n",
    "    if \"REPO_ROOT\" in globals()\n",
    "    else Path(\"./2601_EURO_CORDEX_testing_data\")\n",
    ")\n",
    "\n",
    "# Unzip cache folder (keep it short to avoid Windows path length issues)\n",
    "EUROCORDEX_TEST_UNZIP_ROOT = EUROCORDEX_TESTDATA_ROOT / \"_unzipped\"\n",
    "\n",
    "# Dedicated output root for EURO-CORDEX test results\n",
    "EUROCORDEX_TEST_OUTPUT_ROOT = (\n",
    "    REPO_ROOT / \"outputs\" / \"eurocordex_testing\"\n",
    "    if \"REPO_ROOT\" in globals()\n",
    "    else Path(\"./outputs/eurocordex_testing\")\n",
    ")\n",
    "\n",
    "# Create output directory (safe: ignored by git)\n",
    "EUROCORDEX_TEST_OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DATA:\", EUROCORDEX_TESTDATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c8627-59ef-43bc-aaa4-6f19c4bd36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Unzip EURO-CORDEX test data (zip â†’ _unzipped)\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "zip_root = EUROCORDEX_TESTDATA_ROOT\n",
    "unzip_root = EUROCORDEX_TEST_UNZIP_ROOT\n",
    "\n",
    "zip_files = sorted(zip_root.rglob(\"*.zip\"))\n",
    "print(f\"Found {len(zip_files)} zip file(s)\")\n",
    "\n",
    "for zpath in zip_files:\n",
    "    out_dir = unzip_root / zpath.stem\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"\\nZIP:\", zpath.name)\n",
    "    print(\" -> unpack to:\", out_dir)\n",
    "\n",
    "    with zipfile.ZipFile(zpath, \"r\") as z:\n",
    "        members = [m for m in z.namelist() if not m.endswith(\"/\")]\n",
    "        print(\"   entries:\", len(members))\n",
    "\n",
    "        written = []\n",
    "        for m in members:\n",
    "            target = out_dir / Path(m).name  # flatten: ignore internal paths\n",
    "            with z.open(m) as src:\n",
    "                target.write_bytes(src.read())\n",
    "            written.append(target)\n",
    "\n",
    "    print(\"   written files:\", len(written))\n",
    "    if written:\n",
    "        print(\"   first file:\", written[0].name, \"bytes:\", written[0].stat().st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f76704-3b5b-4358-a715-2be27f94ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r\"C:\\Users\\reinhvlr\\OneDrive\\Documents\\RUB\\Projects\\CARMINE\\Work\\carmine-analyses\\data\\CARMINE-T2.4VR\\CARMINE-T2.4\\2601_EURO_CORDEX_testing_data\\_unzipped\\67a8bafca25cded2f165c94dc94b23ce\\tas_EUR-11_NCC-NorESM1-M_rcp26_r1i1p1_KNMI-RACMO22E_v1_mon_203101-204012.nc\"\n",
    "print(\"len(path) =\", len(p))\n",
    "print(\"len(dir)  =\", len(p.rsplit(\"\\\\\", 1)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a68dbe-6831-45b0-b0c9-72b111901eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Inventory (unzipped NetCDFs): files, timesteps, time coverage, data origin\n",
    "# =============================================================================\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "UNZIP_ROOT = EUROCORDEX_TEST_UNZIP_ROOT\n",
    "print(\"UNZIP_ROOT:\", UNZIP_ROOT)\n",
    "\n",
    "nc_files = sorted([p for p in UNZIP_ROOT.rglob(\"*\") if p.suffix.lower() in (\".nc\", \".nc4\", \".cdf\")])\n",
    "print(f\"Found {len(nc_files)} NetCDF file(s) under {UNZIP_ROOT}\")\n",
    "\n",
    "def _first_attr(ds: xr.Dataset, keys: list[str]) -> str | None:\n",
    "    for k in keys:\n",
    "        if k in ds.attrs and ds.attrs.get(k) not in (None, \"\"):\n",
    "            return str(ds.attrs.get(k))\n",
    "    return None\n",
    "\n",
    "def summarize_netcdf(fp: Path) -> dict:\n",
    "    fp = Path(fp)\n",
    "    row = {\n",
    "        \"zip_folder\": fp.parent.name,          # extracted zip stem folder\n",
    "        \"file_name\": fp.name,\n",
    "        \"path\": str(fp),\n",
    "        \"bytes\": fp.stat().st_size,\n",
    "        \"vars\": None,\n",
    "        \"dims\": None,\n",
    "        \"n_time\": None,\n",
    "        \"time_start\": None,\n",
    "        \"time_end\": None,\n",
    "        # \"data origin\" / provenance (best-effort from global attrs)\n",
    "        \"institution\": None,\n",
    "        \"source\": None,\n",
    "        \"driving_model\": None,\n",
    "        \"rcm_model\": None,\n",
    "        \"ensemble_member\": None,\n",
    "        \"experiment\": None,\n",
    "        \"domain\": None,\n",
    "        \"grid\": None,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # decode_times=True should be fine for monthly; if it ever fails, we still capture n_time\n",
    "        ds = xr.open_dataset(fp, decode_times=True)\n",
    "        try:\n",
    "            row[\"vars\"] = \",\".join(list(ds.data_vars.keys()))\n",
    "            row[\"dims\"] = \",\".join([f\"{k}:{v}\" for k, v in ds.sizes.items()])\n",
    "\n",
    "            if \"time\" in ds.sizes:\n",
    "                row[\"n_time\"] = int(ds.sizes[\"time\"])\n",
    "            if \"time\" in ds.coords and ds.sizes.get(\"time\", 0) > 0:\n",
    "                try:\n",
    "                    t0 = pd.to_datetime(ds[\"time\"].values[0])\n",
    "                    t1 = pd.to_datetime(ds[\"time\"].values[-1])\n",
    "                    row[\"time_start\"] = str(t0)\n",
    "                    row[\"time_end\"] = str(t1)\n",
    "                except Exception:\n",
    "                    row[\"time_start\"] = str(ds[\"time\"].values[0])\n",
    "                    row[\"time_end\"] = str(ds[\"time\"].values[-1])\n",
    "\n",
    "            row[\"institution\"] = _first_attr(ds, [\"institution\", \"institute_id\"])\n",
    "            row[\"source\"] = _first_attr(ds, [\"source\", \"title\"])\n",
    "            row[\"driving_model\"] = _first_attr(ds, [\"driving_model_id\", \"driving_model\"])\n",
    "            row[\"rcm_model\"] = _first_attr(ds, [\"model_id\", \"rcm_model\", \"regional_model_id\"])\n",
    "            row[\"ensemble_member\"] = _first_attr(ds, [\"driving_model_ensemble_member\", \"ensemble_member\", \"realization\"])\n",
    "            row[\"experiment\"] = _first_attr(ds, [\"experiment_id\", \"scenario\", \"scenario_id\"])\n",
    "            row[\"domain\"] = _first_attr(ds, [\"domain_id\", \"CORDEX_domain\"])\n",
    "            row[\"grid\"] = _first_attr(ds, [\"grid\", \"grid_label\"])\n",
    "\n",
    "        finally:\n",
    "            ds.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        row[\"vars\"] = \"ERROR\"\n",
    "        row[\"dims\"] = \"ERROR\"\n",
    "        row[\"experiment\"] = f\"ERROR: {e}\"\n",
    "\n",
    "    return row\n",
    "\n",
    "if not nc_files:\n",
    "    warnings.warn(\"No NetCDFs found. Did the unzip cell run successfully?\")\n",
    "else:\n",
    "    rows = [summarize_netcdf(fp) for fp in nc_files]\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Key view (compact)\n",
    "    key_cols = [\n",
    "        \"zip_folder\", \"file_name\", \"n_time\", \"time_start\", \"time_end\",\n",
    "        \"experiment\", \"driving_model\", \"rcm_model\", \"ensemble_member\",\n",
    "        \"institution\", \"source\", \"domain\", \"grid\",\n",
    "        \"vars\", \"dims\",\n",
    "    ]\n",
    "    display(df[key_cols])\n",
    "\n",
    "    # Optional: quick counts by origin fields\n",
    "    display(\n",
    "        df.groupby([\"experiment\", \"driving_model\", \"rcm_model\"], dropna=False)\n",
    "          .size()\n",
    "          .reset_index(name=\"n_files\")\n",
    "          .sort_values(\"n_files\", ascending=False)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d5c99-501f-4b48-b24e-255b60424752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
